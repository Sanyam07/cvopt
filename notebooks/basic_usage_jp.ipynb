{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================\n",
    "   \n",
    "__コンテンツ__\n",
    "* サーチ方法\n",
    "   1. モジュールインポートとデータロード\n",
    "   2. パラメータサーチ範囲の設定\n",
    "   3. 特徴量選択範囲の設定 (optional)\n",
    "   4. サーチの実行\n",
    "   \n",
    "* ログ使用方法\n",
    "   1. サーチ結果の抽出\n",
    "   2. スタッキングのためのメタ特徴量生成\n",
    "   \n",
    "========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サーチ方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. モジュールインポートとデータロード\n",
    "ここではサンプルデータとして\"the breast cancer wisconsin dataset\"（2値分類）を使用する。\n",
    "はじめにデータセットをTrain, Testで分割する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os ,sys\n",
    "import numpy as np, pandas as pd, scipy as sp\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from cvopt.model_selection import SimpleoptCV\n",
    "from cvopt.search_setting import search_category, search_numeric\n",
    "\n",
    "dataset = datasets.load_breast_cancer()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(dataset.data, dataset.target, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Train features shape:\", Xtrain.shape)\n",
    "print(\"Test features shape:\", Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "output_notebook() # When you need search visualization, need run output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. パラメータサーチ範囲の設定\n",
    "設定は、各cvクラス共通の書式で行うことが可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"penalty\": search_category(['l1', 'l2']),\n",
    "    \"C\": search_numeric(0.01, 3.0, \"float\"), \n",
    "    \"tol\" : search_numeric(0.0001, 0.001, \"float\"),  \n",
    "    \"class_weight\" : search_category([None, \"balanced\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A その他の書式\n",
    "各cvクラスのベースモジュールと同様の方法の書式も使用可能。 \n",
    "\n",
    "### for HyperoptCV (base module: Hyperopt)\n",
    "```python\n",
    "param_distributions = {\n",
    "    \"penalty\": hp.choice(\"penalty\", [\"l1\", \"l2\"]),\n",
    "    \"C\": hp.loguniform(\"C\", 0.01, 3.0), \n",
    "    \"tol\" : hp.loguniform(\"tol\", 0.0001, 0.001), \n",
    "    \"class_weight\" : hp.choice(\"class_weight\", [None, \"balanced\"]),\n",
    "    }\n",
    "```\n",
    "### for  BayesoptCV (base module: GpyOpt)\n",
    "__NOTE:__\n",
    "* GpyOptでは、サーチ範囲を辞書のリストで設定するが、本モジュールでは辞書の辞書(key:param name, value:dict{GpyOpt標準のサーチ範囲設定辞書})で設定を行う。\n",
    "* カテゴリカルのパラメータの場合、サーチ範囲設定辞書に key:`categories`, value:`カテゴリ名一覧リスト` を追加する必要がある。\n",
    "```python\n",
    "param_distributions = {\n",
    "    \"penalty\" : {\"name\": \"penalty\", \"type\":\"categorical\", \"domain\":(0,1), \"categories\":[\"l1\", \"l2\"]},\n",
    "    \"C\": {\"name\": \"C\", \"type\":\"continuous\", \"domain\":(0.01, 3.0)}, \n",
    "    \"tol\" : {\"name\": \"tol\", \"type\":\"continuous\", \"domain\":(0.0001, 0.001)}, \n",
    "    \"class_weight\" : {\"name\": \"class_weight\", \"type\":\"categorical\", \"domain\":(0,1), \"categories\":[None, \"balanced\"]},\n",
    "    }\n",
    "```\n",
    "\n",
    "### for  GASearchCV, RandomoptCV\n",
    "__NOTE:__\n",
    "* サポート対象は`search_setting.search_numeric`, `search_setting.search_category`, `scipy.stats`クラスになる。\n",
    "```python\n",
    "param_distributions = {\n",
    "    \"penalty\" : hp.choice(\"penalty\", [\"l1\", \"l2\"]),\n",
    "    \"C\": sp.stats.randint(low=0.01, high=3.0), \n",
    "    \"tol\" : sp.stats.uniform(loc=0.0001, scale=0.00009),  \n",
    "    \"class_weight\" :  hp.choice(\"class_weight\", [None, \"balanced\"],\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特徴量選択範囲の設定 (optional)\n",
    "特徴量選択は`feature_group`毎に行う。   \n",
    "__もし`feature_group`が\"-100\"であれば、そのグループの特徴量は必ず選択される。__   \n",
    "グループを分ける方法は例えばランダム、特徴量エンジニアリング方法の違い、データソースの違いがある。\n",
    "`feature_group`を設定しない場合、全ての特徴量が使用される。\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "### Example.   \n",
    "データが5個の特徴量（カラム）を持っていて、以下のように`feature_group`を設定するとする。\n",
    "   \n",
    "| feature index(data col index) | feature group |   \n",
    "|:------------:|:------------:|   \n",
    "| 0 | 0 |\n",
    "| 1 | 0 |\n",
    "| 2 | 0 |\n",
    "| 3 | 1 |\n",
    "| 4 | 1 |\n",
    "   \n",
    "この場合、以下のようにlistを定義する。   \n",
    "   \n",
    "```\n",
    "feature_groups = [0, 0, 0, 1, 1]\n",
    "```\n",
    "\n",
    "サーチの結果として, `feature_group`毎に選択したかどうかを表すbooleanが得られる。\n",
    "   \n",
    "```\n",
    "feature_groups0: True   \n",
    "feature_groups1: False\n",
    "```\n",
    "\n",
    "この結果は、グループ0の特徴量を使用し、グループ1の特徴量を使用しないという意味になる。\n",
    "\n",
    "------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups = np.random.randint(0, 5, Xtrain.shape[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. サーチの実行\n",
    "cvoptはscikit-learnのcross validationクラスと同様のAPIを持っている。 \n",
    "scikit-learnを使い慣れていれば、cvoptのクラスも簡単に使用することが出来る。\n",
    "   \n",
    "各クラスの詳細は[API reference](https://genfifth.github.io/cvopt/)を参照のこと。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "estimator = LogisticRegression()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "opt = SimpleoptCV(estimator, param_distributions, \n",
    "                 scoring=\"roc_auc\",              # Objective of search\n",
    "                 cv=cv,                          # Cross validation setting\n",
    "                 max_iter=32,                    # Number of search\n",
    "                 n_jobs=3,                       # Number of jobs to run in parallel.\n",
    "                 verbose=2,                      # 0: don't display status, 1:display status by stdout, 2:display status by graph \n",
    "                 logdir=\"./search_usage\",        # If this path is specified, save the log.\n",
    "                 model_id=\"search_usage\",        # used estimator's dir and file name in save.\n",
    "                 save_estimator=2,               # estimator save setting.\n",
    "                 backend=\"hyperopt\",             # hyperopt,bayesopt, gaopt or randomopt.\n",
    "                 )\n",
    "\n",
    "opt.fit(Xtrain, ytrain, validation_data=(Xtest, ytest), \n",
    "        # validation_data is optional.\n",
    "        # This data is only used to compute validation score(don't fit).\n",
    "        # When this data is input & save_estimator=True,the estimator which is fitted whole Xtrain is saved.\n",
    "        feature_groups=feature_groups, \n",
    "        )\n",
    "ytest_pred = opt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(opt.cv_results_).head() # Search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ログ使用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.サーチ結果の抽出\n",
    "cvoptでは、サーチログを簡単に使用するためのヘルパー関数を用意している。\n",
    "サーチ結果を使用したい場合、以下のように実行可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvopt.utils import extract_params\n",
    "estimator_params, feature_params, feature_select_flag  = extract_params(logdir=\"./search_usage\", \n",
    "                                                                        model_id=\"search_usage\", \n",
    "                                                                        target_index=0, \n",
    "                                                                        feature_groups=feature_groups)\n",
    "\n",
    "estimator.set_params(**estimator_params)         # Set estimator parameters\n",
    "Xtrain_selected = Xtrain[:, feature_select_flag] # Extract selected feature columns\n",
    "\n",
    "print(estimator)\n",
    "print(\"Train features shape:\", Xtrain.shape)\n",
    "print(\"Train selected features shape:\",Xtrain_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. スタッキングのためのメタ特徴量生成\n",
    "メタ特徴量を使用し、 [stacking](https://mlwave.com/kaggle-ensembling-guide/)をしたい場合、以下のようにメタ特徴量を取得できる。\n",
    "   \n",
    "これを行う場合、サーチ時にパラメータ`save_estimator`を0より大きくすることで、各cv-foldを実施した際のestimatorを保存する必要がある。 \n",
    "加えて、fitしていない特徴量に対するメタ特徴量を生成したい場合、パラメータ`save_estimator`を1より大きくすることで、全trainデータでfitしたestimatorを保存する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvopt.utils import mk_metafeature\n",
    "Xtrain_meta, Xtest_meta = mk_metafeature(Xtrain, ytrain, \n",
    "                                         logdir=\"./search_usage\", \n",
    "                                         model_id=\"search_usage\", \n",
    "                                         target_index=0, \n",
    "                                         cv=cv, \n",
    "                                         validation_data=(Xtest, ytest), \n",
    "                                         feature_groups=feature_groups, \n",
    "                                         estimator_method=\"predict_proba\")\n",
    "\n",
    "print(\"Train features shape:\", Xtrain.shape)\n",
    "print(\"Train meta features shape:\", Xtrain_meta.shape)\n",
    "print(\"Test features shape:\", Xtest.shape)\n",
    "print(\"Test meta features shape:\",  Xtest_meta.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

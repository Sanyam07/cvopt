{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random\n",
    "import numpy as np, pandas as pd, tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn import datasets\n",
    "\n",
    "import keras.backend as K\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.models import Sequential, Input, Model, save_model, clone_model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from cvopt.model_selection import SimpleoptCV\n",
    "from cvopt.search_setting import search_category, search_numeric\n",
    "\n",
    "# fix seed\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(0)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "output_notebook() # When you need search visualization, need run output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sample code for cifar10 (image data, classification)\n",
    "cvopt support estimator like scikit-learn.   \n",
    "So, when keras.wrappers.scikit_learn is used, cvopt is available in keras.   \n",
    "In this case, __saver__ and __scorer__ for keras must be defined.   \n",
    "\n",
    "## Note\n",
    "### parallel execution\n",
    "cvopt parallel backend is `multiprocessing` and `multiprocessing` with Keras have problem depend on execution environment.    \n",
    "If problem occured, try `n_jobs` = `1`.\n",
    "\n",
    "### feature selection\n",
    "In feature selection, input shape is changed. But, basic Keras model's input shape is fixed and is not available to feature selection.   \n",
    "If need feature selection, must make model input shape variable.\n",
    "\n",
    "### Resource exhausted\n",
    "Sometimes an Resource exhausted error occurs in gpu environment. One countermeasure to this error is to clear the session at a certain timing.\n",
    "When use cvopt and keras.wrappers.scikit_learn, there is an implementation example as follows(1.5 Run all backend search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(Xtrain, ytrain), (Xtest, ytest) = cifar10.load_data()\n",
    "Xtrain = Xtrain.astype(\"float32\") / 255\n",
    "Xtest = Xtest.astype(\"float32\") / 255\n",
    "ytrain = to_categorical(ytrain)\n",
    "ytest = to_categorical(ytest)\n",
    "\n",
    "n_classes = 10\n",
    "def mk_nw(activation, lr, out_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=5, strides=1, activation=activation, input_shape=Xtrain.shape[1:]))\n",
    "    model.add(MaxPool2D(2, strides=2))\n",
    "\n",
    "    model.add(Conv2D(50, kernel_size=5, strides=1, activation=activation))\n",
    "    model.add(MaxPool2D(2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(out_dim, activation=activation))\n",
    "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=lr))\n",
    "    return model\n",
    "estimator = KerasClassifier(mk_nw, activation=\"linear\", lr=0.01, out_dim=256, epochs=16, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Scorer\n",
    "`KerasClassifier.fit` need ytrue is 1hot(n_samples, n_classes) and `KerasClassifier.predict` return label(n_samples, ).   \n",
    "While basic score function (`score(ytrue, ypred)`) need that ytrue and ypred are the same expression(1hot or label).   \n",
    "Therefore, for `KerasClassifier`, scorer that inputs are ytrue(1hot) and pred(label) must be defined.    \n",
    "In the define, use `sklearn.metrics.make_scorer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "def acc(ytrue, ypred):\n",
    "    return accuracy_score(np.argmax(ytrue, axis=1), ypred)\n",
    "scorer = make_scorer(acc,  greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Saver\n",
    "When save estimator, cvopt use `sklearn.externals.joblib.dump` in default.   \n",
    "But saving Keras model by joblib is not recommended.\n",
    "So, saver for Keras need to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "\n",
    "def saver(estimator, path):\n",
    "    save_model(estimator.model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"activation\": search_category([\"linear\", \"relu\"]),\n",
    "    \"lr\":  search_numeric(0.0001, 0.1, \"float\"),  \n",
    "    \"out_dim\" : search_numeric(124, 512, \"int\"),  \n",
    "    }\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "opt = SimpleoptCV(estimator, param_distributions, \n",
    "                  scoring=scorer, \n",
    "                  cv=cv, \n",
    "                  max_iter=8, \n",
    "                  n_jobs=1,\n",
    "                  verbose=2, \n",
    "                  logdir=\"./cifar10\", \n",
    "                  model_id=\"search_usage\", \n",
    "                  save_estimator=2, \n",
    "                  saver=saver, \n",
    "                  backend=\"hyperopt\", \n",
    "                  )\n",
    "opt.fit(Xtrain, ytrain, validation_data=(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Log usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvopt.utils import extract_params\n",
    "estimator_params, feature_params, feature_select_flag  = extract_params(logdir=\"./cifar10\", \n",
    "                                                                        model_id=\"search_usage\", \n",
    "                                                                        target_index=0, \n",
    "                                                                        feature_groups=None)\n",
    "\n",
    "estimator.set_params(**estimator_params)         # Set estimator parameters\n",
    "print(estimator.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvopt.utils import mk_metafeature\n",
    "from keras.models import load_model\n",
    "\n",
    "Xtrain_meta, Xtest_meta = mk_metafeature(Xtrain, ytrain, \n",
    "                                         logdir=\"./cifar10\", \n",
    "                                         model_id=\"search_usage\", \n",
    "                                         target_index=0, \n",
    "                                         cv=cv, \n",
    "                                         validation_data=(Xtest, ytest), \n",
    "                                         feature_groups=None, \n",
    "                                         estimator_method=\"predict\", \n",
    "                                         loader=load_model  # loader for Keras\n",
    "                                         )\n",
    "\n",
    "print(\"Train features shape:\", Xtrain.shape)\n",
    "print(\"Train meta features shape:\", Xtrain_meta.shape)\n",
    "print(\"Test features shape:\", Xtest.shape)\n",
    "print(\"Test meta features shape:\",  Xtest_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Run all backend search\n",
    "To Resource exhausted countermeasure, clear session before fit. In the follows, when clear session,  model(graph) is cleared at the same time. So, saving of model does not work well in saver. If need saving model, please consider using keras callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrgKerasClassifier(KerasClassifier):\n",
    "    def fit(self, *args, **kwargs):\n",
    "        KTF.clear_session()\n",
    "        session = tf.Session(\"\")\n",
    "        KTF.set_session(session)\n",
    "        super().fit(*args, **kwargs)\n",
    "\n",
    "n_classes = 10\n",
    "def mk_nw(activation, lr, out_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(20, kernel_size=5, strides=1, activation=activation, input_shape=Xtrain.shape[1:]))\n",
    "    model.add(MaxPool2D(2, strides=2))\n",
    "\n",
    "    model.add(Conv2D(50, kernel_size=5, strides=1, activation=activation))\n",
    "    model.add(MaxPool2D(2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(out_dim, activation=activation))\n",
    "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=lr))\n",
    "    return model\n",
    "estimator = OrgKerasClassifier(mk_nw, activation=\"linear\", lr=0.01, out_dim=256, epochs=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"activation\": search_category([\"linear\", \"relu\"]),\n",
    "    \"lr\":  search_numeric(0.0001, 0.1, \"float\"),  \n",
    "    \"out_dim\" : search_numeric(124, 512, \"int\"),  \n",
    "    }\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "for bk in [\"bayesopt\", \"randomopt\", \"hyperopt\", \"gaopt\"]:\n",
    "    opt = SimpleoptCV(estimator, param_distributions, \n",
    "                      scoring=scorer, \n",
    "                      cv=cv, \n",
    "                      max_iter=16, \n",
    "                      n_jobs=1,\n",
    "                      verbose=1, \n",
    "                      logdir=\"./cifar10_all\", \n",
    "                      model_id=bk, \n",
    "                      save_estimator=0, \n",
    "                      backend=bk, \n",
    "                      )\n",
    "    opt.fit(Xtrain, ytrain, validation_data=(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Sample for  the breast cancer wisconsin (matrix data, classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_breast_cancer()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(dataset.data, dataset.target, test_size=0.3, random_state=0)\n",
    "ytrain = to_categorical(ytrain)\n",
    "ytest = to_categorical(ytest)\n",
    "\n",
    "n_classes = 2\n",
    "def mk_nw(activation, lr, out_dim):\n",
    "    inputs = Input(shape=Xtrain.shape[1:]) \n",
    "    x = Dense(out_dim)(inputs)\n",
    "    x = Dense(n_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=lr))\n",
    "    return model\n",
    "estimator = KerasClassifier(mk_nw, activation=\"linear\", lr=0.01, out_dim=8, epochs=16, verbose=0)\n",
    "\n",
    "param_distributions = {\n",
    "    \"activation\": search_category([\"linear\", \"relu\"]),\n",
    "    \"lr\":  search_numeric(0.0001, 0.1, \"float\"),  \n",
    "    \"out_dim\" : search_numeric(124, 512, \"int\"),  \n",
    "    }\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "opt = SimpleoptCV(estimator, param_distributions, \n",
    "                  scoring=make_scorer(lambda ytrue, ypred: accuracy_score(np.argmax(ytrue, axis=1), ypred), greater_is_better=True), \n",
    "                  cv=cv, \n",
    "                  max_iter=8, \n",
    "                  n_jobs=1,\n",
    "                  verbose=2, \n",
    "                  logdir=\"./bcw\", \n",
    "                  model_id=\"search_usage\", \n",
    "                  save_estimator=2, \n",
    "                  saver=lambda model, path: save_model(model.model, path), \n",
    "                  backend=\"hyperopt\", \n",
    "                  )\n",
    "\n",
    "opt.fit(Xtrain, ytrain, validation_data=(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvopt.utils import extract_params\n",
    "estimator_params, feature_params, feature_select_flag  = extract_params(logdir=\"./bcw\", \n",
    "                                                                        model_id=\"search_usage\", \n",
    "                                                                        target_index=0, \n",
    "                                                                        feature_groups=None)\n",
    "\n",
    "estimator.set_params(**estimator_params)  # Set estimator parameters\n",
    "print(estimator.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvopt.utils import mk_metafeature\n",
    "from keras.models import load_model\n",
    "\n",
    "Xtrain_meta, Xtest_meta = mk_metafeature(Xtrain, ytrain, \n",
    "                                         logdir=\"./bcw\", \n",
    "                                         model_id=\"search_usage\", \n",
    "                                         target_index=0, \n",
    "                                         cv=cv, \n",
    "                                         validation_data=(Xtest, ytest), \n",
    "                                         feature_groups=None, \n",
    "                                         estimator_method=\"predict\", \n",
    "                                         loader=load_model # loader for keras\n",
    "                                         )\n",
    "\n",
    "print(\"Train features shape:\", Xtrain.shape)\n",
    "print(\"Train meta features shape:\", Xtrain_meta.shape)\n",
    "print(\"Test features shape:\", Xtest.shape)\n",
    "print(\"Test meta features shape:\",  Xtest_meta.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
